{"name": "bioimageio format validation", "source_name": "/home/bioengine/apps/model-runner/models/stupendous-sheep/rdf.yaml", "id": "stupendous-sheep", "type": "model", "format_version": "0.4.10", "status": "failed", "details": [{"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "perform_io_checks": true, "known_files": {"MitoNet_v1_weights.pth": "ca9f7de681c94b1e89d20cab21ec39135415fc2c8798292cd1f0f6a33aa1e18b"}, "update_hashes": false, "root": "/home/bioengine/apps/model-runner/models/stupendous-sheep"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.4.10", "status": "passed", "loc": [], "errors": [], "warnings": [{"loc": ["name"], "msg": "Name longer than 64 characters.", "type": "warning", "severity": 20}, {"loc": ["weights", "pytorch_state_dict", "dependencies"], "msg": "Custom dependencies (pip:./requirements.txt) specified. Avoid this whenever possible to allow execution in a wider range of software environments.", "type": "warning", "severity": 30}], "context": {"file_name": "rdf.yaml", "perform_io_checks": true, "known_files": {"MitoNet_v1_weights.pth": "ca9f7de681c94b1e89d20cab21ec39135415fc2c8798292cd1f0f6a33aa1e18b"}, "update_hashes": false, "root": "/home/bioengine/apps/model-runner/models/stupendous-sheep"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Has expected resource type", "status": "passed", "loc": ["type"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "The provided filename /tmp/tmpdlheew4_/MitoNet_v1.pth does not exist", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   113 \u2502   \u2502   if isinstance(weight_spec, v0_4.PytorchStateDictWeightsDescr)                      \u2502\n\u2502   114 \u2502   \u2502   else weight_spec.architecture.kwargs                                               \u2502\n\u2502   115 \u2502   )                                                                                      \u2502\n\u2502 \u2771 116 \u2502   torch_model = custom_callable(**model_kwargs)                                          \u2502\n\u2502   117 \u2502                                                                                          \u2502\n\u2502   118 \u2502   if not isinstance(torch_model, nn.Module):                                             \u2502\n\u2502   119 \u2502   \u2502   if isinstance(                                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/tmpdlheew4_/infer_2d_6e0598690940b79b3e6dbc95cd28c42490c0be562f741b4e865b1d69e0a82641.py:57 \u2502\n\u2502                                                                                                  \u2502\n\u2502 [Errno 2] No such file or directory: '/tmp/tmpdlheew4_/infer_2d_6e0598690940b79b3e6dbc95cd28c424 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899 \u2502\n\u2502                                                                                                  \u2502\n\u2502   150 \u2502   \"\"\"                                                                                    \u2502\n\u2502   151 \u2502   if isinstance(f, (str, os.PathLike)):                                                  \u2502\n\u2502   152 \u2502   \u2502   if not os.path.exists(f):  # type: ignore[type-var]                                \u2502\n\u2502 \u2771 153 \u2502   \u2502   \u2502   raise ValueError(f\"The provided filename {f} does not exist\")  # type: ignore[ \u2502\n\u2502   154 \u2502   \u2502   if os.path.isdir(f):                                                               \u2502\n\u2502   155 \u2502   \u2502   \u2502   raise ValueError(f\"The provided filename {f} is a directory\")  # type: ignore[ \u2502\n\u2502   156                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nValueError: The provided filename /tmp/tmpdlheew4_/MitoNet_v1.pth does not exist\n", "traceback_html": "<!DOCTYPE html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #bfbf7f; text-decoration-color: #bfbf7f}\n.r5 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r6 {color: #0000ff; text-decoration-color: #0000ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #00ffff; text-decoration-color: #00ffff}\n.r9 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #808000; text-decoration-color: #808000; font-weight: bold}\n.r12 {color: #800000; text-decoration-color: #800000; font-style: italic}\n.r13 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r14 {color: #800080; text-decoration-color: #800080}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<html>\n<body>\n    <code>\n        <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">642 \u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">643 \u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">644 \u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r5\">\u2502   \u2502   </span><span class=\"r6\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">646 \u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">647 \u2502   \u2502   </span>) <span class=\"r6\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">648 \u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">368 \u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r8\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">369 \u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">370 \u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r5\">\u2502   </span>model_adapter = model_adapter <span class=\"r9\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">372 \u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">373 \u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">374 \u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r9\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">166 \u2502   \u2502   </span><span class=\"r6\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">167 \u2502   \u2502   </span><span class=\"r6\">if</span> <span class=\"r8\">len</span>(weight_format_priority_order) == <span class=\"r6\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">168 \u2502   \u2502   \u2502   </span><span class=\"r6\">assert</span> <span class=\"r8\">len</span>(errors) == <span class=\"r6\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r5\">\u2502   \u2502   \u2502   </span><span class=\"r6\">raise</span> errors[<span class=\"r6\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">170 \u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">171 \u2502   \u2502   </span><span class=\"r6\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">172 \u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">109 \u2502   \u2502   \u2502   \u2502   </span><span class=\"r6\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">110 \u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r6\">from</span> <span class=\"r10\">.pytorch_backend</span> <span class=\"r6\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">111 \u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r5\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r6\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">114 \u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">115 \u2502   \u2502   \u2502   \u2502   </span><span class=\"r6\">except</span> <span class=\"r8\">Exception</span> <span class=\"r6\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 35 \u2502   \u2502   \u2502   </span><span class=\"r6\">raise</span> <span class=\"r8\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 36 \u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 37 \u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r5\">\u2502   \u2502   </span><span class=\"r8\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r6\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 39 \u2502   \u2502   </span><span class=\"r6\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 40 \u2502   \u2502   \u2502   </span><span class=\"r8\">self</span>._model = <span class=\"r8\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\"> 41 \u2502   \u2502   </span><span class=\"r6\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">113 \u2502   \u2502   </span><span class=\"r6\">if</span> <span class=\"r8\">isinstance</span>(weight_spec, v0_4.PytorchStateDictWeightsDescr)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">114 \u2502   \u2502   </span><span class=\"r6\">else</span> weight_spec.architecture.kwargs                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">115 \u2502   </span>)                                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>116 <span class=\"r5\">\u2502   </span>torch_model = custom_callable(**model_kwargs)                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">117 \u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">118 \u2502   </span><span class=\"r6\">if</span> <span class=\"r9\">not</span> <span class=\"r8\">isinstance</span>(torch_model, nn.Module):                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">119 \u2502   \u2502   </span><span class=\"r6\">if</span> <span class=\"r8\">isinstance</span>(                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/tmpdlheew4_/</span><span class=\"r11\">infer_2d_6e0598690940b79b3e6dbc95cd28c42490c0be562f741b4e865b1d69e0a82641.py</span>:<span class=\"r6\">57</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r12\">[Errno 2] No such file or directory: &#x27;/tmp/tmpdlheew4_/infer_2d_6e0598690940b79b3e6dbc95cd28c424</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/tmp/ray/session_2025-10-15_06-37-59_627288_1/runtime_resources/pip/68786a3844c33f8cbab707301899</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">150 </span><span class=\"r4\">\u2502   </span><span class=\"r7\">&quot;&quot;&quot;</span>                                                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">151 \u2502   </span><span class=\"r6\">if</span> <span class=\"r8\">isinstance</span>(f, (<span class=\"r8\">str</span>, os.PathLike)):                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">152 \u2502   \u2502   </span><span class=\"r6\">if</span> <span class=\"r9\">not</span> os.path.exists(f):  <span class=\"r5\"># type: ignore[type-var]</span>                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>153 <span class=\"r5\">\u2502   \u2502   \u2502   </span><span class=\"r6\">raise</span> <span class=\"r8\">ValueError</span>(<span class=\"r7\">f&quot;The provided filename {</span>f<span class=\"r7\">} does not exist&quot;</span>)  <span class=\"r5\"># type: ignore[</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">154 \u2502   \u2502   </span><span class=\"r6\">if</span> os.path.isdir(f):                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">155 \u2502   \u2502   \u2502   </span><span class=\"r6\">raise</span> <span class=\"r8\">ValueError</span>(<span class=\"r7\">f&quot;The provided filename {</span>f<span class=\"r7\">} is a directory&quot;</span>)  <span class=\"r5\"># type: ignore[</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r5\">156 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r13\">ValueError: </span>The provided filename <span class=\"r14\">/tmp/tmpdlheew4_/</span><span class=\"r9\">MitoNet_v1.pth</span> does not exist\n</pre>\n    </code>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": [{"pip": ["bioimageio.core", "empanada-dl>=0.1.5", "imagecodecs", "scikit-image>=0.18"]}, "pip"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help          Show this help message and exit.\n  -v, --verbose       Can be used multiple times. Once for detailed output,\n                      twice for INFO logging, thrice for DEBUG logging, four\n                      times for TRACE logging.\n  --no-plugins        Disable all plugins that are not built into conda.\n  -V, --version       Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate          Activate a conda environment.\n    clean             Remove unused packages and caches.\n    compare           Compare packages between conda environments.\n    config            Modify configuration values in .condarc.\n    content-trust     Signing and verification tools for Conda\n    create            Create a new conda environment from a list of specified\n                      packages.\n    deactivate        Deactivate the current active conda environment.\n    doctor            Display a health report for your environment.\n    export            Export a given environment\n    info              Display information about current conda install.\n    init              Initialize conda for shell interaction.\n    install           Install a list of packages into a specified conda\n                      environment.\n    list              List installed packages in a conda environment.\n    notices           Retrieve latest channel notifications.\n    package           Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)\n                      Remove a list of packages from a specified conda\n                      environment.\n    rename            Rename an existing environment.\n    repoquery         Advanced search for repodata.\n    run               Run an executable in a conda environment.\n    search            Search for packages and display associated information\n                      using the MatchSpec format.\n    update (upgrade)  Update conda packages to the latest compatible version.\n"}], "env": [["bioimageio.core", "0.9.0", "", ""], ["bioimageio.spec", "0.5.4.3", "", ""]], "saved_conda_list": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help          Show this help message and exit.\n  -v, --verbose       Can be used multiple times. Once for detailed output,\n                      twice for INFO logging, thrice for DEBUG logging, four\n                      times for TRACE logging.\n  --no-plugins        Disable all plugins that are not built into conda.\n  -V, --version       Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate          Activate a conda environment.\n    clean             Remove unused packages and caches.\n    compare           Compare packages between conda environments.\n    config            Modify configuration values in .condarc.\n    content-trust     Signing and verification tools for Conda\n    create            Create a new conda environment from a list of specified\n                      packages.\n    deactivate        Deactivate the current active conda environment.\n    doctor            Display a health report for your environment.\n    export            Export a given environment\n    info              Display information about current conda install.\n    init              Initialize conda for shell interaction.\n    install           Install a list of packages into a specified conda\n                      environment.\n    list              List installed packages in a conda environment.\n    notices           Retrieve latest channel notifications.\n    package           Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)\n                      Remove a list of packages from a specified conda\n                      environment.\n    rename            Rename an existing environment.\n    repoquery         Advanced search for repodata.\n    run               Run an executable in a conda environment.\n    search            Search for packages and display associated information\n                      using the MatchSpec format.\n    update (upgrade)  Update conda packages to the latest compatible version.\n"}